# AI Readiness Assessment — Final Likert-Optimized Version (Team-Focused)

## 1. Strategy & Culture  
*How intentionally AI is positioned, communicated, and supported for the team.*

- Leadership regularly communicates to my team why AI matters for the business and for specific roles over the next 12 months.
- Leadership and managers have discussed and aligned with the team on which roles AI supports and which roles may change because of AI.
- Employees in my team generally feel safe using AI in their daily work without fear of judgment or negative consequences.
- Leadership has communicated where and how AI is expected to be used in everyday work, and my team refers to this guidance in practice.
- Failed or imperfect AI experiments in the team are usually discussed with a focus on learning rather than blame.

---

## 2. Data, Infrastructure & Governance  
*How well data, systems, and rules enable the team to use AI responsibly.*

- My team works with clearly identified data sources that are used in our AI use cases.
- The data used by the team for AI is generally clean, up to date, and usable without excessive manual effort.
- There are clear rules about which data must not be shared with AI tools, and my team mostly follows them in practice.
- AI tools used by the team are connected to data sources through integrations or APIs in most cases, rather than manual copy-paste.
- Known infrastructure limitations are explicitly considered when my team decides how and where to use AI.

---

## 3. Tools & Automation  
*How consistently AI tools are embedded into the team’s daily workflows.*

- AI tools are used regularly as part of my team’s daily work, not only for one-off experiments.
- Team members actively review AI outputs and know when human judgment is required.
- My team consciously chooses between AI assistants and more autonomous agents depending on task complexity and risk.
- There are recurring tasks where AI saves the team noticeable time on a regular basis.
- The team periodically reassesses its AI tool stack and adjusts it as needs and constraints change.

---

## 4. Skills & Learning  
*How systematically AI skills are developed and supported within the team.*

- Required AI skills are defined for different roles in my team, at least at a high level.
- Some team members consistently create clear and effective instructions or prompts for AI tools.
- New team members are introduced to existing AI practices during onboarding, even if only at a basic level.
- AI outputs produced by the team are usually reviewed and validated rather than accepted without checks.
- The team has a shared understanding of which AI-related skills are currently missing or underdeveloped.

---

## 5. Product & Processes  
*How AI contributes to value creation in the team’s work.*

- My team can point to specific parts of the product or service where AI creates tangible value.
- AI improves not only speed, but also quality or user experience in some of the team’s core processes.
- Processes that require a human-in-the-loop are defined and generally followed by the team.
- Changes to workflows caused by AI adoption are documented or explained well enough for the team to follow.
- When using AI, the team consciously balances speed, quality, and reliability rather than optimizing for speed alone.

---

## 6. Security & Compliance  
*How risks, responsibility, and safeguards are handled in the team’s AI usage.*

- Team members are generally aware of risks related to uncontrolled or careless AI usage.
- Rules for safe and compliant AI use exist and are applied by the team in most everyday situations.
- Responsibility for decisions and mistakes involving AI is clearly assigned to people, not to tools.
- The team’s AI usage aligns with client expectations, legal requirements, and regulatory constraints.
- There is a known process the team can follow to pause, limit, or roll back AI solutions if issues arise.

---

## 7. Experimentation & Innovation  
*How structured and intentional AI experimentation is within the team.*

- AI experiments run by the team are usually framed as hypotheses with a clear expected outcome.
- Most AI experiments have a defined timeframe and some criteria for success or failure.
- Failed AI experiments are reviewed by the team and lead to concrete learnings.
- The team has some protected time or space to experiment with AI alongside delivery work.
- The team consciously decides which AI experiments to scale further and which to stop.

---

## 8. Integration & Scaling  
*How reliably the team’s AI solutions can be sustained and expanded.*

- AI solutions used by the team do not depend on a single individual to operate or evolve.
- Successful AI solutions from the team can be reused or adapted by other teams with reasonable effort.
- AI solutions are maintained by the team after launch, not only during initial rollout.
- The team has a reasonable understanding of what currently limits further AI scaling.
- AI initiatives fit into the broader system and architecture the team works within, rather than existing as isolated add-ons.

---

## 9. Impact Measurement  
*How clearly the team measures and prioritizes AI impact.*

- Success metrics are defined for AI initiatives before or shortly after the team starts them.
- The team can point to concrete improvements that are largely attributable to AI usage.
- The team distinguishes between local efficiency gains and broader business impact.
- AI initiatives involving the team are prioritized and resourced alongside other projects based on expected value.
- Leadership is willing to stop AI initiatives involving the team if they do not deliver meaningful results over time.
