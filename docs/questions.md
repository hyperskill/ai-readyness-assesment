# AI Readiness Assessment â€” Simplified Version

## 1. Strategy & Culture
- We can clearly explain why AI matters for our team next year.
- We understand which roles AI will support and which may change.
- Using AI is seen as normal work practice, not as cheating.
- We have agreed where AI use is expected, not optional.
- Failed AI experiments do not lead to blame or punishment.

## 2. Data & Infrastructure
- We know which data is needed for our AI use cases.
- Our data is clean and up to date enough for AI use.
- We clearly know which data must not be shared with AI tools.
- We can connect AI tools to our data without manual copy-paste.
- We understand current infrastructure limits and work within them.

## 3. Tools & Automation
- AI tools are part of our daily workflow.
- We know when AI helps and when it can mislead us.
- We clearly distinguish between AI assistants and autonomous agents.
- We have tasks where AI already saves significant time.
- We regularly review and update our AI tool stack.

## 4. Skills & Learning
- We know which AI skills are needed for each role in the team.
- Some team members can clearly and precisely give tasks to AI.
- New hires are introduced to our AI practices during onboarding.
- We know the difference between using AI and checking its output.
- We clearly see which AI skills we are missing today.

## 5. Product & Processes
- We can point to where AI creates real value in our product or service.
- AI improves not only speed but also quality or user experience.
- We know which processes require a human in the loop.
- AI-driven process changes are documented and explained.
- We consciously balance speed and reliability when using AI.

## 6. Security & Compliance
- The team understands risks of uncontrolled AI usage.
- We have clear rules on what data can and cannot be used with AI.
- Responsibility for AI mistakes is clearly defined.
- Our AI usage does not violate client or regulatory requirements.
- We know how to quickly stop or roll back harmful AI solutions.

## 7. Experimentation & Innovation
- We define AI experiments with clear expected outcomes.
- Experiments have time limits and success criteria.
- Failed experiments still produce useful learning.
- The team has dedicated time for AI experimentation.
- We know which experiments to scale and which to stop.

## 8. Integration & Scaling
- AI solutions do not depend on a single key person.
- We can reuse AI solutions across teams with little effort.
- AI solutions are maintained after launch.
- We understand what currently blocks AI scaling.
- AI initiatives fit into our overall system architecture.

## 9. Impact Measurement
- We define success metrics before starting AI initiatives.
- We can show which improvements came specifically from AI.
- We distinguish team-level gains from business-level impact.
- AI initiatives compete for resources like any other project.
- We are ready to stop AI projects that do not deliver value.
